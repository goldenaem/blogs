{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "audio_path = librosa.util.example_audio_file()\n",
    "y, sr = librosa.load(audio_path)\n",
    "x = np.arange(0, len(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_point, n_fft = 3000, 2048\n",
    "plt.plot(x[start_point:start_point+n_fft], y[start_point:start_point+n_fft])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.abs(librosa.stft(y))\n",
    "print(D.shape, np.max(D), np.min(D), np.mean(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\n",
    "plt.plot(D[:,1])\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(D, y_axis='linear', x_axis='time')\n",
    "plt.title('Spectrogram')\n",
    "plt.colorbar(format=\"%+2.0f\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max), y_axis='linear', x_axis='time')\n",
    "plt.title('power Spectrogram')\n",
    "plt.colorbar(format=\"%+2.0f db\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_128 = librosa.filters.mel(sr=sr, n_fft=2048, n_mels=128)\n",
    "plt.figure(figsize=(15, 4));\n",
    "\n",
    "plt.subplot(1, 3, 1);\n",
    "librosa.display.specshow(mel_128, sr=sr, hop_length=512, x_axis='linear');\n",
    "plt.ylabel('Mel filter');\n",
    "plt.colorbar();\n",
    "plt.title('1. Our filter bank for converting from Hz to mels.');\n",
    "\n",
    "plt.subplot(1, 3, 2);\n",
    "mel_10 = librosa.filters.mel(sr=sr, n_fft=2048, n_mels=10)\n",
    "librosa.display.specshow(mel_10, sr=sr, hop_length=512, x_axis='linear');\n",
    "plt.ylabel('Mel filter');\n",
    "plt.colorbar();\n",
    "plt.title('2. Easier to see what is happening with only 10 mels.');\n",
    "\n",
    "plt.subplot(1, 3, 3);\n",
    "idxs_to_plot = [0, 9, 49, 99, 127]\n",
    "for i in idxs_to_plot:\n",
    "\tplt.plot(mel_128[i]);\n",
    "plt.legend(labels=[f'{i+1}' for i in idxs_to_plot]);\n",
    "plt.title('3. Plotting some triangular filters separately.');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D[:,1])\n",
    "plt.plot(mel_128.dot(D[:,1]))\n",
    "plt.legend(labels=['spectrum', 'mel-spectrum'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(log_mel_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.title('mel power spectrogram')\n",
    "plt.colorbar(format=\"%+02.0f dB\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./GTZAN\"\n",
    "csv_list = []\n",
    "genres = []\n",
    "for genre in os.listdir(root_dir):\n",
    "    if os.path.isdir(os.path.join(root_dir, genre)):\n",
    "        genres.append(genre)\n",
    "        for wav_file in os.listdir(os.path.join(root_dir, genre)):\n",
    "            csv_list.append([os.path.join(root_dir, genre, wav_file), genre])\n",
    "df = pd.DataFrame(csv_list, columns=['path', 'genre'])\n",
    "df.to_csv(os.path.join(root_dir, \"meta.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_idx_dict = dict()\n",
    "g = np.array(genres)\n",
    "for genre in genres:\n",
    "    # genre_idx_dict[genre] = np.argwhere(g==genre)[0] # for index\n",
    "    genre_idx_dict[genre] = np.array(g==genre, dtype=np.int64) # for one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    \"\"\"\n",
    "    GTZAN Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, csv_file, sample_rate=32000, wave_size = 32000*10, n_fft=2048, hop_length=512, win_length=2048, n_mels=128, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          csv_file (string) : GTZAN의 meta csv가 저장된 path\n",
    "          transform (callable, optional) : 샘플에 적용될 optional transform\n",
    "          wave_size : default wave crop size\n",
    "          spec_size : default spectrogram crop size(according to time axis)\n",
    "        \"\"\"\n",
    "        self.path_genre_dict = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.wav_npy_path = os.path.join(self.root_dir, 'wavs.npy')\n",
    "        self.spec_npy_path = os.path.join(self.root_dir, 'specs.npy')\n",
    "        self.genre_npy_path = os.path.join(self.root_dir, 'genres.npy')\n",
    "\n",
    "        # prepare(save/load) numpy array before batch iter\n",
    "        if os.path.exists(self.wav_npy_path) and os.path.exists(self.spec_npy_path) and os.path.exists(self.genre_npy_path):\n",
    "            self.wavs = np.load(self.wav_npy_path)\n",
    "            self.specs = np.load(self.spec_npy_path)\n",
    "            self.genres = np.load(self.genre_npy_path)\n",
    "        else:\n",
    "            self.wavs, self.specs, self.genres = [], [], []\n",
    "            for i in range(len(self.path_genre_dict)):\n",
    "                wav_name, genre = self.path_genre_dict.iloc[i]\n",
    "                wav, sr = librosa.load(wav_name, sr=self.sample_rate)\n",
    "                genre_label = genre_idx_dict[genre]\n",
    "                spec = librosa.feature.melspectrogram(y=wav[:wav_size], sr=sr, n_fft=n_fft, hop_length=hop_length, win_length=win_length, n_mels=n_mels)\n",
    "                spec = librosa.power_to_db(spec, ref=np.max)\n",
    "                self.wavs.append(wav[:wav_size])\n",
    "                self.specs.append(spec)\n",
    "                self.genres.append(genre_label)\n",
    "            self.wavs = np.array(self.wavs)\n",
    "            self.specs = np.array(self.specs)\n",
    "            self.genres = np.array(self.genres)\n",
    "            np.save(self.wav_npy_path, self.wavs)\n",
    "            np.save(self.spec_npy_path, self.specs)\n",
    "            np.save(self.genre_npy_path, self.genres)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_genre_dict)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = {\n",
    "            'wav' : self.wavs[idx],\n",
    "            'spec' : self.specs[idx],\n",
    "            'genre' : self.genres[idx],\n",
    "            'sample_rate' : self.sample_rate\n",
    "        }    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"\n",
    "    random crop from sample data\n",
    "    mode = \"wav\" or \"spec\" or \"comb\"\n",
    "    \"\"\"\n",
    "    def __init__(self, wav_crop_size, spec_crop_size, mode):\n",
    "        self.wav_crop_size = wav_crop_size\n",
    "        self.spec_crop_size = spec_crop_size\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Assuming that the sample is wave/mel-spectrogram, crop randomly\n",
    "        \"\"\"\n",
    "        try:\n",
    "            wav, spec, genre = sample['wav'], sample['spec'], sample['genre']\n",
    "            if self.mode == 'wav' or self.mode == 'comb':\n",
    "                wav_len = len(wav)\n",
    "                if wav_len > self.wav_crop_size:\n",
    "                    start_frame = np.random.randint(0, wav_len - self.wav_crop_size)\n",
    "                    wav = wav[start_frame:start_frame+self.wav_crop_size]\n",
    "                elif wav_len == self.wav_crop_size:\n",
    "                    pass\n",
    "                else :\n",
    "                    raise Exception(\"wave length is shorter than crop size!\")\n",
    "\n",
    "            if self.mode == 'spec' or self.mode == 'comb':\n",
    "                spec_len = spec.shape[-1]\n",
    "                if spec_len > self.spec_crop_size:\n",
    "                    start_frame = np.random.randint(0, spec_len - self.spec_crop_size)\n",
    "                    spec = spec[:, start_frame:start_frame+self.spec_crop_size]\n",
    "                elif spec_len == self.spec_crop_size:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise Exception(\"spectrogram length is shorter than crop size!\")\n",
    "\n",
    "            return {'wav':wav, 'spec':spec, \"genre\":genre}\n",
    "\n",
    "        except Exception as error:\n",
    "            print(\"RandomCrop Transform error : \" + repr(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_dataset = GTZANDataset(\n",
    "    root_dir=root_dir, \n",
    "    csv_file=os.path.join(root_dir, 'meta.csv'),\n",
    "    transform = transforms.Compose([\n",
    "            RandomCrop(wav_crop_size = 320000, spec_crop_size = 600, mode=\"comb\"),\n",
    "        ])\n",
    "    )\n",
    "dataset_size = len(gtzan_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(0.3 * dataset_size)) # 0.3 is test set ratio\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "trn_indices, tst_indices = indices[split:], indices[:split]\n",
    "\n",
    "trn_gtzan_dataset = torch.utils.data.sampler.SubsetRandomSampler(trn_indices)\n",
    "tst_gtzan_dataset = torch.utils.data.sampler.SubsetRandomSampler(tst_indices)\n",
    "\n",
    "trn_gtzan_dataloader = DataLoader(gtzan_dataset, batch_size = 16, drop_last=True,sampler=trn_gtzan_dataset)\n",
    "val_gtzan_dataloader = DataLoader(gtzan_dataset, batch_size = 16, drop_last=True,sampler=tst_gtzan_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trn_gtzan_dataloader : \n",
    "    wavs, specs, genres = batch['wav'], batch['spec'], batch['genre']\n",
    "    print(wavs.shape, specs.shape, genres.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
